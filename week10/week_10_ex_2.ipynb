{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 (6 Points): Imbalanced Data\n",
    "\n",
    "##### As already discussed, our toy data set is quite imbalanced (much more non-returns than returns). In the lecture we discussed the concept of under-sampling the training data. Implement now your own code for under-sampling the training data to balance the classes (= do not use the sklearn for this) . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.read_csv('data/data.csv')\n",
    "transactions.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "transactions = transactions[['totalAmount','c_0','c_1','c_2','c_3','c_4','c_5', 'returnLabel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = transactions.drop('returnLabel',axis=1)\n",
    "y = transactions.returnLabel\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prepare balanced training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows: 1310\n",
      "number of returns: 655\n"
     ]
    }
   ],
   "source": [
    "count_return = sum(y_train)\n",
    "y_train_pd = y_train.to_frame()\n",
    "non_return_indices = y_train_pd[y_train_pd.returnLabel == 0].index\n",
    "random_indices = np.random.choice(non_return_indices,count_return, replace=False)\n",
    "return_indices = y_train_pd[y_train_pd.returnLabel == 1].index\n",
    "under_sample_indices = np.concatenate([return_indices,random_indices])\n",
    "under_sample = transactions.loc[under_sample_indices]\n",
    "print(\"number of rows:\",under_sample.shape[0])\n",
    "print(\"number of returns:\",count_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Learn a RandomForest model on the balanced training data and compare the performance in terms of accuracy on the test data to the performance of a model that was learned on the original data.\n",
    "###### Remark: The test data must not be balanced (it should always reflect the real distribution of the data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained with original data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      9042\n",
      "           1       0.33      0.23      0.27       258\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      9300\n",
      "   macro avg       0.65      0.61      0.63      9300\n",
      "weighted avg       0.96      0.97      0.96      9300\n",
      "\n",
      "Accuracy with original data: 0.9656989247311828\n"
     ]
    }
   ],
   "source": [
    "compare_model = RandomForestClassifier(n_estimators=100)\n",
    "compare_model.fit(X_train, y_train)\n",
    "\n",
    "pred_compare = compare_model.predict(X_test)\n",
    "\n",
    "print(\"Trained with original data\")\n",
    "print(classification_report(y_test,pred_compare))\n",
    "print(\"Accuracy with original data:\",metrics.accuracy_score(y_test, pred_compare))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained with balanced data\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.89      9042\n",
      "           1       0.11      0.84      0.19       258\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      9300\n",
      "   macro avg       0.55      0.82      0.54      9300\n",
      "weighted avg       0.97      0.80      0.87      9300\n",
      "\n",
      "Accuracy with undersampled data: 0.803763440860215\n"
     ]
    }
   ],
   "source": [
    "X_train_under = under_sample.drop('returnLabel',axis=1)\n",
    "y_train_under = under_sample.returnLabel\n",
    "\n",
    "under_model = RandomForestClassifier(n_estimators=100)\n",
    "under_model.fit(X_train_under, y_train_under)\n",
    "\n",
    "pred_full_test = under_model.predict(X_test)\n",
    "\n",
    "print(\"Trained with balanced data\")\n",
    "print(classification_report(y_test,pred_full_test))\n",
    "print(\"Accuracy with undersampled data:\",metrics.accuracy_score(y_test, pred_full_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
